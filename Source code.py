# -*- coding: utf-8 -*-
"""Data_mining_exam_elib_frib.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1n0UdQ-5pbg8-nUuQ5bMRWH6oS23wpiTp

Imports
"""

# Linear algebra
import numpy as np

# Data processing and CSV file
import pandas as pd

# Data visualization
import matplotlib.pyplot as plt

# Algorithms from Scikit Learn
from sklearn import tree
from sklearn.tree import DecisionTreeClassifier
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import KBinsDiscretizer, StandardScaler
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import classification_report, accuracy_score
from sklearn.decomposition import PCA

# Read data from CSV file
url = 'https://raw.githubusercontent.com/fribl/DataMining_ITU/master/Covid%20_Data.csv'
df = pd.read_csv(url)

"""#A look into the dataset"""

# View dimensions
df.shape

# Preview dataset
df.head()

# Get info about dataset
df.info()

# Find null values
df.isnull().sum()

# View details about age
df['AGE'].describe()

"""#Pre-processing

Feature selection
"""

# Drop columns
df = df.drop(columns=["USMER", "MEDICAL_UNIT", "OTHER_DISEASE"])

# Rename columns
df.rename(columns = {'HIPERTENSION':'HYPERTENSION'}, inplace = True)
df.rename(columns = {'INTUBED':'INTUBATED'}, inplace = True)
df.rename(columns = {'DATE_DIED':'DIED'}, inplace = True)

"""Data cleaning"""

df["INTUBATED"].value_counts()

df["ICU"].value_counts()

print("Value counts of INTUBATED column for patients that where not hospitalized: \n", df.query('PATIENT_TYPE==1')['INTUBATED'].value_counts())
print("Value counts of ICU column for patients that where not hospitalized: \n", df.query('PATIENT_TYPE==1')['ICU'].value_counts())

df["PREGNANT"].value_counts()

print("Value counts of PREGNANT column for men: \n", df.query('SEX==2')['PREGNANT'].value_counts())
print("Value counts of PREGNANT column for women: \n", df.query('SEX==1')['PREGNANT'].value_counts())

# Clean INTUBATED, ICU, and PREGNANT columns for missing values
df['INTUBATED'] = df['INTUBATED'].replace(97,2)

df['ICU'] = df['ICU'].replace(97,2)

df['PREGNANT'] = df['PREGNANT'].replace(97,2)
df['PREGNANT'] = df['PREGNANT'].replace(98,2)

# Remove missing values (97, 98, 99)
cols = ["SEX", "PATIENT_TYPE", "INTUBATED", "PNEUMONIA", "PREGNANT", "DIABETES", "COPD", "ASTHMA", "INMSUPR", "HYPERTENSION",
"CARDIOVASCULAR", "OBESITY", "RENAL_CHRONIC", "TOBACCO", "ICU"]

for col in cols:
    df = df.loc[df[col] <= 2]

# Histogram for detect outliers on AGE coloum
df['AGE'].plot.hist()

# Clean columns with persons who tested positive
df = df.loc[df["CLASIFFICATION_FINAL"] < 4]

"""Data transformation"""

# Transform DATE_DIED to binary values
def deathdate(x):
    if x in "9999-99-99":
        return 2
    else:
        return 1

df["DIED"] = df["DIED"].apply(lambda x : deathdate(x))

# View dimensions after pre-processing
df.shape

# Take sample of 2000 data points
data = df.sample(n=2000, replace=False, random_state=1)
#data = data.reset_index()
data.head()

"""Data visualization"""

# Histogram with age bin size 20
age = data[["AGE"]]
age = age.to_numpy().flatten()

fig = plt.figure(figsize=(5, 6))
ax = fig.add_axes([0,0,1,1])
ax.set_axisbelow(True)
plt.hist(age, bins=20, rwidth=0.9, color=["tab:blue"])
plt.xlabel('Age', fontsize=14)
plt.ylabel('Number of people', fontsize=14)
plt.grid(True)

# Method to visualize features in pies

def pie(data, feature, labels):
    counts = data[feature].value_counts()
    print(counts)
    one = counts[1]
    two = counts[2]
    sizes = [one, two]
    fig1, ax1 = plt.subplots()
    ax1.pie(sizes, labels=labels, autopct='%1.1f%%', colors=["tab:blue", "skyblue"], textprops={'fontsize': 14})
    ax1.axis('equal')

    plt.show()

# Pie chart of survivors and deaths
pie(data, "DIED", ["Died", "Survived"])

# Pie chart of males and females
pie(data, "SEX", ["Female", "Male"])

# Pie chart of not hospitalized and hospitalized persons
pie(data, "PATIENT_TYPE", ["Not hospitalized", "Hospitalized"])

# Pie chart of intubated and not intubated persons
pie(data, "INTUBATED", ["Intubated", "Not intubated"])

"""#Model 1: Pipeline with Decision Tree

Pipeline
"""

col_trans = ColumnTransformer(transformers=[
    ("bin_age", KBinsDiscretizer(encode='ordinal'), ["AGE"]),
    ], remainder="passthrough")

pipeline = Pipeline(steps=[
    ("column_transformer", col_trans),
    ("model", DecisionTreeClassifier())
    ])

"""Grid search"""

X = data[["AGE", "SEX", "PATIENT_TYPE", "INTUBATED", "ICU", "PNEUMONIA", "PREGNANT", "DIABETES",
"COPD", "ASTHMA", "INMSUPR", "HYPERTENSION", "CARDIOVASCULAR", "OBESITY", "RENAL_CHRONIC",
"TOBACCO"]]
y = data[["DIED"]]

# Splitting data in training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)

# Grid search to find best hyperparameters
param_grid = {
    "column_transformer__bin_age__strategy": ["uniform", "quantile", "kmeans"],
    "column_transformer__bin_age__n_bins": [4,5,6,7,8,10],
    "model__criterion": ("gini", "entropy"),
    "model__min_samples_split": [2, 4, 6],
    "model__min_samples_leaf": [8, 10, 12, 14, 16, 18, 20]
}

grid = GridSearchCV(pipeline, param_grid, n_jobs=2)
model1 = grid.fit(X_train, y_train)

# Print best parameters found from grid search
print("Best parameters =", model1.best_params_)
# Print bin edges
print(model1.best_estimator_[0].transformers_[0][1].bin_edges_)

"""##Results

Performance
"""

# Makes predictions based on test set, and calc. accuracy
y_pred = grid.best_estimator_.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
class_report = classification_report(y_test, y_pred)

print("Accuracy on test data:", accuracy)
print(class_report)

"""Visualization of decision tree"""

print("Depth of full tree:", model1.best_estimator_[1].get_depth())

best = model1.best_estimator_.fit(X_train, y_train)
fn = ["AGE", "SEX", "PATIENT_TYPE", "INTUBATED", "ICU", "PNEUMONIA", "PREGNANT", "DIABETES","COPD", "ASTHMA", "INMSUPR", "HYPERTENSION", "CARDIOVASCULAR", "OBESITY", "RENAL_CHRONIC","TOBACCO"]

fig = plt.figure(figsize=(25,20))
_ = tree.plot_tree(best[1], feature_names=fn, filled = True)

"""Overview of feature importance

"""

def featureImportancePlot(feat_imp, df_columns):
    importance_df = pd.DataFrame(list(df_columns), feat_imp)
    importance_df.columns = ["Feature_Names"]
    importance_df["Importances"] = importance_df.index
    importance_df.index = np.arange(0,len(importance_df))
    importance_df = importance_df.sort_values(by = "Importances", ascending = False)
    importance_df

    size = len(feat_imp)/3
    fig = plt.figure(figsize=(4, size))
    ax = fig.add_axes([0,0,1,1])
    ax.set_axisbelow(True)
    ax.set_facecolor("white")
    ax.grid(color = "gainsboro", linewidth = 1)
    ax.barh(importance_df["Feature_Names"], importance_df["Importances"], color="tab:blue")
    ax.set_xlabel('Gini impurity')
    ax.set_title('Feature Importance')
    ax.invert_yaxis()

    plt.show()

# Run function on first model
featureImportancePlot(model1.best_estimator_[1].feature_importances_, X.columns)

"""#Model 2: Pipeline with Principal Component Analysis and Decision Tree

Pipeline & Grid search
"""

def model(X, y):
    print("------------------------------")
    print("Features: {}".format(X.columns))

    search_space = [x for x in range(1, len(X.columns))]
    print()

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)

    #pipeline with best parameters from first model
    col_trans = ColumnTransformer(transformers=[
        ("bin_age", KBinsDiscretizer(encode='ordinal', strategy="uniform", n_bins=4), ["AGE"]),
        ], remainder="passthrough")

    pipeline_w_pca = Pipeline(steps=[
        ("column_transformer", col_trans),
        ("scalar", StandardScaler()),
        ("pca", PCA()),
        ("model", DecisionTreeClassifier(criterion="entropy", min_samples_split=4, min_samples_leaf=12))
        ])

    # Grid search to find best hyperparameters
    param_grid = {
        "pca__n_components": search_space
    }

    # Search best model
    grid = GridSearchCV(pipeline_w_pca, param_grid, n_jobs=2)
    model = grid.fit(X_train, y_train)
    best_model = model.best_estimator_.fit(X_train, y_train)

    # Performance of the best model
    y_pred = model.best_estimator_.predict(X_test)
    report = classification_report(y_test, y_pred)
    accuracy = accuracy_score(y_test, y_pred)

    print("Search space for PCA n_components:", search_space, "| Best parameters =", model.best_params_, "| ACCURACY:", accuracy)

    return best_model, report

"""##Results

Performance
"""

# For running experiments:
# pca_X_all = data[["AGE", "SEX", "PATIENT_TYPE", "INTUBATED", "ICU", "PNEUMONIA", "PREGNANT", "DIABETES",
# "COPD", "ASTHMA", "INMSUPR", "HYPERTENSION", "CARDIOVASCULAR", "OBESITY", "RENAL_CHRONIC",
# "TOBACCO"]]

pca_X_8f = data[["PATIENT_TYPE", "INTUBATED", "PNEUMONIA","AGE", "SEX", "DIABETES", "HYPERTENSION", "OBESITY"]]
pca_X_7f = data[["PATIENT_TYPE", "INTUBATED", "PNEUMONIA","AGE", "SEX", "DIABETES", "HYPERTENSION"]]
pca_X_6f = data[["PATIENT_TYPE", "INTUBATED", "PNEUMONIA","AGE", "SEX", "DIABETES"]]
pca_X_5f = data[["PATIENT_TYPE", "INTUBATED", "PNEUMONIA","AGE", "SEX"]]
pca_X_4f = data[["PATIENT_TYPE", "INTUBATED", "PNEUMONIA","AGE",]]

pca_y = data[["DIED"]]

#model_all, report_all, X_train_all = model(pca_X_all, pca_y)
best_model_8, report_8 = model(pca_X_8f, pca_y)
best_model_7, report_7 = model(pca_X_7f, pca_y)
best_model_6, report_6 = model(pca_X_6f, pca_y)
best_model_5, report_5 = model(pca_X_5f, pca_y)
best_model, report_4 = model(pca_X_4f, pca_y)

# Print report from experiment with 4 features, because it produced the best accuracy
print(report_4)

"""Visualization of Decision Tree after PCA"""

print("Depth of full tree:", best_model[3].get_depth())

fn = ["PC1"]

fig = plt.figure(figsize=(25,20))
_ = tree.plot_tree(best_model[3], feature_names=fn, filled = True)